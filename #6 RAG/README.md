RAG(Retrieval Augmented Generation, 검색 증강 생성) : 개인으로부터 제공된 data를 사용하거나 탐색함으로써 Language Model의 능력을 확장

# LLM이란?
Large Language Model의 약자로, 자연어 처리(NLP)에서 사용되는 인공지능 기술의 한 종류이다. 이 모델들은 대규모의 텍스트 데이터를 학습하여 언어의 구조와 의미를 이해하고, 그 학습을 바탕으로 텍스트 생성, 번역, 요약, 질문에 대한 답변 등 다양한 언어 관련 작업을 할 수 있다.

## LLM의 주요 특징
- 방대한 지식 보유 : 다양한 분야의 텍스트를 학습하여 광범위한 지식을 갖추고 있다.
- 문맥 이해 능력 : 단순히 단어를 매칭하는 것이 아니라 전후 맥락을 고려하여 언어를 이해할 수 있다.
- 자연어 생성 능력 : 문장 생성, 질문 응답, 요약, 번역 등 다양한 자연어 처리 태스크를 수행할 수 있다.
- 전이 학습 능력 : 한 분야에서 학습한 지식을 다른 유사 태스크에 활용하는 등 전이 학습이 가능하다.
- 확장성 : 더 많은 데이터와 컴퓨팅 자원을 활용하면 계속 성능을 향상시킬 수 있다.

LLM은 챗봇, 검색 엔진, 콘텐츠 생성 등 다양한 분야에서 활용되고 있으며, 인간과 유사한 수준의 언어 이해와 생성 능력을 보여주고 있다. 하지만 편향된 문제, 사실 관계 오류 등의 한계점도 지적되고 있어 해결해야 할 과제도 남아있는 상황이다.

## LLM의 장점
1. 광범위한 지식 활용
: 방대한 양의 텍스트 데이터를 학습하여 다양한 분야의 지식을 습득, 학습한 지식을 바탕으로 사용자의 질문에 폭넓고 심도 있는 답변 가능
2. 뛰어난 언어 이해 및 생성 능력
: 단어 간의 관계와 문맥을 고려하여 자연스러운 언어 이해 가능, 문법적으로 정확하고 의미 있는 문장 생성 능력
3. 다양한 태스크 수행 가능
: 텍스트 분류, 질의응답, 요약, 번역, 문장 생성 등 다양한 NLP 태스크 처리 가능, 하나의 모델로 여러 태스크를 수행할 수있어 범용성이 높다.
4. 사용자 친화적인 인터페이스
: 자연어로 된 사용자 입력을 이해하고 응답할 수 있어 접근성이 좋고, 챗봇, 가상 어시스턴트 등으로 활용되어 사용자 경험 향상
5. 다양한 분야에서의 활용
: 고객 서비스, 콘텐츠 제작, 교육, 의료 등 다양한 산업 분야에서 활용 가능, 사람과 기계간의 상호작용을 향상시키고 업무 효율성 증대에 기여한다.

## LLM의 단점
1. 편향성 문제 : 학습 데이터에 내재된 편향성을 그대로 반영할 수 있고, 성별, 인종, 종교 등에 대한 고정관념이나 차별적 표현을 생성할 위험 존재
2. 사실 관계 오류 가능성 : 방대한 데이터를 학습하지만, 항상 정확한 정보를 제공하지는 않고, 잘못된 정보나 허위 정보를 진실로 간주하고 전파할 수 있다.
3. 맥락 이해의 한계 : 문장 단위의 이해는 가능하지만, 장문의 글이나 복잡한 맥락 파악은 어려울 수 있고, 세계 지식과 상식 추론 능력이 부족하여 심층적인 이해에 한계가 존재한다.
4. 일관성 문제 : 동일한 입력에 대해 일관된 답변을 생성하지 않을 수 있고, 모델의 확률적 특성상 생성 결과가 매번 달라질 수 있어 신뢰성 저하
5. 윤리적 문제 : 악용 가능성이 존재하며, 책임 소재 파악이 어려울 수 있고, 모델의 출력의 결과에 대한 통제와 검증 체계 마련이 필요하다.

# RAG는 LLM의 단점 중 무엇을 개선하는가?
RAG(Retrieval-Augmented Generation)는 LLM의 단점 중 '사실 관계 오류 가능성'과 '맥락 이해의 한계'를 개선하는 데 초점을 맞춘 방법이다. RAG는 LLM에 외부 지식 베이스를 연결하여 모델의 생성 능력과 사실 관계 파악 능력을 향상시키는 기술이다.

1. 외부 지식 활용 : 대규모의 구조화된 지식 베이스를 모델에 연결, 주어진 질의에 대한 관련 정보를 지식 베이스에서 검색 및 추출
2. 증거 기반 생성 : 검색된 지식 정보를 증거로 활용하여 보다 사실에 기반한 답변 생성, 생성된 답변의 출처를 명시함으로써 신뢰성 향상
3. 맥락 이해력 향상 : 외부 지식을 통해 질의에 대한 배경 지식과 맥락 정보를 파악, 단순한 패턴 매칭이 아닌 추론 능력을 바탕으로 한 답변 생성

RAG는 기존 LLM의 생성 능력과 외부 지식 베이스의 정보를 결합함으로써, 보다 정확하고 사실에 기반한 답변을 제공할 수 있다. 또한 모델의 출력 결과에 대한 증거를 제시할 수 있어 성명 가능성과 신뢰성을 높일 수 있다.
RAG 기술은 질의응답, 정보 검색, 팩트 체킹 등의 태스크에서 활발히 연구되고 있으며, 구글의 LaMDA, OpenAI의 WebGPT 등 최신 LLM에도 적용되고 있다. 다만 RAG 모델의 성능은 열결된 지식 베이스의 푸밎ㄹ과 커버리지에 크게 의존하므로, 고품질의 지식 베이스 구축이 중요한 과제로 남아 있다.

# RAG의 기본 개념
RAG는 대규모 언어 모델의 한계를 극복하기 위해 제안된 새로운 자연어 처리 기술이다. LLM은 방대한 양의 텍스트 데이터를 사전 학습하여 강력한 언어 이해 및 생성 능력을 갖추고 있지만, 학습 데이터에 없는 최신 정보나 특정 도메인 지식은 제공하기 어렵다는 단점이 있다.
RAG는 이러한 LLM의 한계를 극복하기 위해 '지식 검색'과 '언어 생성'을 결합한 프레임워크이다. RAG의 기본 아이디어는 질문에 답하기 위해 필요한 지식을 외부 데이터베이스에서 검색하여 활용하는 것이다.

## RAG의 주요 구성 요소
1. 질의 인코더 : 사용자의 질문을 이해하기 위한 언어 모델이다. 주어진 질문을 벡터 형태로 인코딩한다.
2. 지식 검색기 : 인코딩된 질문을 바탕으로 외부 지식 베이스에서 관련 정보를 검색한다. 예를 들어 Wikipedia, 뉴스 기사, 전문 서적 등 방대한 문서 집합에서 질문과 연관된 문단이나 구절을 찾아낸다.
3. 지식 증강 생성기 : 검색된 지식을 활용하여 질문에 대한 답변을 생성하는 언어 모델이다. 기존의 LLM과 유사하지만, 검색된 지식을 추가 입력으로 받아 보다 정확하고 풍부한 답변을 생성할 수 있다.

### RAG의 동작 과정 요약
1. 사용자의 질문이 주어지면 질의 인코더가 이를 이해하기 쉬운 형태로 변환한다.
2. 지식 검색기가 인코딩된 질문을 바탕으로 외부 지식 베이스에서 관련 정보를 검색한다.
3. 검색된 지식은 지식 증강 생성기의 입력으로 전달된다.
4. 지식 증강 생성기는 검색된 지식을 활용하여 사용자 질문에 대한 답변을 생성한다.

   
